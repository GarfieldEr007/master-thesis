\chapter{基于互信息的多任务行为识别}
\section{引言}

如本文在第三章所述，目前现存的行为识别方法的一般流程都是提取视频特征再利用特征训练分类器。它们之中的绝大多数将每个行为类别视为一个任务，然后独立的对每个任务 学习其对应的分类模型，从而浪费和忽视了类别之间共享的信息。基于此，第三章中提出了基于~SVM~间隔的多任务行为识别，首先对数据库中的所有任务两两训练~1-VS-1~的~SVM，然后用~SVM~的间隔作为对应的两个类别之间的相似性度量。对相似度矩阵进行聚类后可以得到数据库的潜在的类别结构，最后将此结构作为先验约束与多任务学习框架结合，从而利用任务之间的相关信息提高分类模型的性能和泛化能力。

本章内容在第三章的基础上，对于任务之间的相似度度量做出了更深层次的探索。既然多任务学习的目的是令相似的任务之间分享特征，那么如果从特征的角度来衡量任务之间的相似度将更加的直观和合理。本文使用的特征为Fisher Vector\cite{CaiWPQ14,PengZQP14,OneataVS13}，它近年来被行为识别方法广泛利用并取得了很好的效果。Fisher Vector~ 由高斯混合模型的最大似然函数分别对于均值和协方差的导数串联而成，也就是说~Fisher Vector~中的连续维度对应着一个特定的高斯函数。此外，我们观察到高斯混合模型中每个高斯函数对于不同行为类别的贡献不同，不同的高斯混合模型捕捉和表示了不同的视觉特征和运动特征。在这些观察的基础上，我们提出了一个假设：相似的行为类别分享较多的高斯函数，也就是分享~Fisher Vector~中的对应连续维度的特征。基于此，我们提出了基于互信息的多任务行为识别。首先我们计算出每个高斯函数对于每一个行为类别的互信息作为衡量其对这个类别的重要性权重，如果这个权重过低，那么这个高斯函数对应的特征也被视为无用的。两个类别同时拥有的高斯函数的个数用于衡量类别之间的相似度。通过计算得到所有类别的相似度矩阵之后，再如第三章所说的，通过聚类得到类别之间隐含的特征结构，最后利用基于组结构约束的多任务学习为每个组学习到一个共享的特征空间，具体的流程框架图如图~\ref{p13}~所示。

\begin{figure*}
\begin{center}
%\fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
\includegraphics[width=1\linewidth]{framework2.eps}
\end{center}
   \caption{基于互信息的多任务行为识别的具体流程。}
\label{p13}
\end{figure*}

综上所述，本章提出了一种基于互信息的多任务行为识别方法。本章的主要内容安排如下：在~\ref{42}~节中介绍~Fisher Vector~；在~\ref{43}~节中介绍基于互信息的多任务行为识别，首先会介绍基于互信息的相似性度量，然后简单介绍目标函数的优化；在~\ref{44}~节中进行实验仿真并对实验结果进行分析；在~\ref{45}~节中对本章内容进行总结。

\section{Fisher Vector}
\label{42}
BoVW~是计算机视觉领域常用的特征处理方法，它可以把从视频和图像中提取的局部特征转化为全局特征。BoVW~的具体步骤如图~\ref{p1}~所示，分别为（1）特征提取（2）特征预处理（3）生成码本（4）特征编码（5）特征的池化和正规化。这五个步骤中的每一步都有研究者们提出了许多有效的方法，而其中最重要的步骤当数码本的生成和特征的编码。如果使用高斯混合模型（Gaussin Mixture Model, GMM）来生成码本和基于~Fisher Vector~的方法对特征进行编码，那么最终得到的特征就称为~Fisher Vector~。Fisher Vector~\cite{PerronninSM10} 起源于~Fisher Kernel~。将原始特征通过~Fisher Kernel~映射到高维的特征空间之后得到的向量即为~Fisher Vector~。 下面将分别对~Fisher Kernel~ 和~Fisher Vector~做出简单的介绍。

Fisher Kernel~\cite{PerronninD07} 是分类问题中常用的模型，它结合了生成模型和判别模型的优点。假定给定了样本~$\mathbf{X}$~，它的生成过程可以被建模为一个包含参数~$\lambda$~的概率密度函数~$p$~。在我们的应用中，$\mathbf{X}$~为一个视频样本。则~$\mathbf{X}$~可以被如下的梯度向量所描述：
\begin{equation}
\label{fx}
G_{\lambda}^{\mathbf{X}} = \nabla_{\lambda}\log p(\mathbf{X} \mid \lambda),
\end{equation}
上式中的似然函数的梯度表示了参数~$\lambda$~对于~$\mathbf{X}$~生成过程的贡献。这个梯度向量的维度仅仅和~$\lambda$~向量的维度相关。基于上述梯度向量，定义核函数
\begin{equation}
\label{f20}
K(\mathbf{X},\mathbf{Y}) = G_{\lambda} ^ {\mathbf{X}'}F_{\lambda}^{-1}G_{\lambda}^\mathbf{Y},
\end{equation}
其中~$F_{\lambda}$~为~$p$~的~Fisher~信息矩阵：

\begin{equation}
\label{f21}
F_{\lambda} = E_{x \sim p}\left< \nabla_{\lambda}\log p(x \mid \lambda) \nabla_{\lambda}\log p(x \mid \lambda)^{'} \right>,
\end{equation}
其中~$F_{\lambda}$~是对称且正定的矩阵，它的柯勒斯基（Cholesy）分解为~$F_{\lambda} = F_{\lambda}^{'}F_{\lambda}$~，则可得正规化向量：
\begin{equation}
\label{f21}
g_{\lambda}^{X} = L_{\lambda}G_{\lambda}^{X},
\end{equation}
公式~\eqref{f20}~可被重写为~$g_{\lambda}^{\mathbf{X}}$~的点乘形式，其中~$g_{\lambda}^{\mathbf{X}}$~即为样本~$\mathbf{X}$~的~Fisher Vector。 从上面的分析可以看出将原始样本映射到特征空间上得到的特征向量，就是最终的~Fisher Vector~。

假设样本~$\mathbf{X} = \{x_t, t = 1,2,...,T\}$~表示从视频中提取的描述子，其中~$T$~为描述子的个数，而~$\mathbf{X}$~的生成过程可由~$p$~所独立描述。$p$~为概率密度函数，它可以有很多的形式，通常将它选择为高斯混合模型:
\begin{equation}
\label{f22}
p(x) = \sum_{i=1}^N w_i p_i(x),
\end{equation}
GMM~中的每一个元素~$p_i$~都是独立的高斯函数，它可以视为~BoVW~码本中的一个单词（word），每个~$p_i$~都捕捉了不同的视觉特征和运动特征，$N$~表示了码本的大小。在下面的文章中，我们统一将码本中的词称为高斯函数。令参数~$\bm{\lambda} = \{w_i,\bm{\mu}_i,\bm{\sum}_i, i = 1,2,...,N\}$~，其中~$w_i, \bm{\mu}_i$~和~$\bm{\sum}_i$~分别表示第~$i$~个高斯函数的权重，均值和协方差均值。假设协方差矩阵~$\bm{\sum}_i$~为对角矩阵，则可以用方差向量的平方~$\bm{\sigma}_i^2$~表示协方差矩阵。可以用最大似然函数估计（Maximum Likelihood Estimation）在一系列样本的基础上训练得到~GMM~~$p(x)$~，通常使用~EM~算法迭代解决这个问题。

GMM~和~K-means~算法一样，是~BoVW~中生成码本的一种方法。GMM~与~K-means~方法的不同之处在于，后者是一种硬聚类方法，即它必须将特征描述子划分给码本中确切的一个词，但是前者可以通过~EM~算法给出描述子属于码本中每个词的可能性，所以~GMM~是一种软聚类方法，它比~K-means~算法更加的灵活，它不仅仅描述了码本中词的信息，而且还描述了码本分布情况。

已知~Fisher Vector~由公式~\eqref{fx}~的似然函数的梯度向量对于参数~$\lambda$~的导数串联而成。将~GMM~带入公式~\eqref{fx}~可得
\begin{equation}
\label{f23}
\begin{split}
&\bm{\rho}_i = \frac{1}{\sqrt{\pi_i}}\gamma_i \left(\frac{\bf{x}-\bm{\mu}_i}{\bm{\sigma}_i} \right), \\
&\bm{\tau}_i = \frac{1}{\sqrt{2\pi_i}}\gamma_i\left[ \frac{(\bf{x}-\bm{\mu}_i)^2}{\bm{\sigma_i^2}} - 1\right],
\end{split}
\end{equation}
其中~$\gamma_{k} = p(k \mid x_t)$~表示局部描述子属于第~$k$~个高斯函数的权重：
\begin{equation}
\label{f24}
\gamma_k = \frac{\pi_k \mathcal{N}(x;\bm{\mu}_k,\bm{\sigma}_k)} {\sum_{i=1}^{K} \pi_i \mathcal{N}(x; \bm{\mu}_i,\bm{\sigma}_i)}.
\end{equation}

在公式~\eqref{f23}~中~$\bm{\rho}_i$~和~$\bm{\tau}_i$~表示第~$i$~个高斯函数分别对于均值~$\bm{\mu}_i$~和协方差矩阵~$\bm{\sigma}_i^2$~ 的导数。这两个向量的维数和描述子的维数相同。将它们串联起来可得
\begin{equation}
\label{f25}
\mathbf{g}_{\lambda}^{\mathbf{X}}=[\bm{\rho}_1,\bm{\tau}_1,...,\bm{\rho}_N,\bm{\tau}_N].
\end{equation}
$\mathbf{g}_{\lambda}^{\mathbf{X}}$~这个~$2ND$~维度的向量即为描述~$\mathbf{X}$~的~Fisher Vector~。

Fisher Vector~相对于传统的词袋方法的优势在于，后者得到的是一个极其稀疏的向量，它只关注了关键词的数量信息，所以是一个~0~阶的统计信息；Fisher Vector~并不稀疏，同时，除了描述子的~0~阶信息，Fisher Vector~还包含了~1~阶（期望）信息、2~阶（方差信息），因此~Fisher Vector~是一个高维的向量特征。由于~Fisher Vector~保留了码本中每个词更丰富的信息，所以码本的大小也比传统的词袋方法要小。终上所述，Fisher Vector~是一个高维且包含了更多信息的特征。

\section{基于互信息的多任务行为识别}
\label{43}
在上一小节中，我们介绍了~Fisher Vector~，知道了它事实上由GMM的最大似然函数分别对于均值和协方差的导数串联而成，如图~\ref{p13}~所示~Fisher Vector~中的连续维度特征对应着一个特定的高斯函数。基于每个高斯函数都捕捉了视频的不同特征和相似的视频类别之间又共享相同的特征这两个假设，我们提出了基于互信息的多任务行为识别，首先利用互信息来衡量行为类别之间的相似度并探索了数据库中潜藏的类别结构信息，最后将此结构信息作为多任务学习的先验正则项来识别行为。

\subsection{基于互信息的相似性度量}
\label{431}
本小节主要描述了一种基于互信息的衡量两个行为类别之间相似度的方法。首先将视频表示为~Fisher Vector~，计算每个高斯函数对于每个行为类别的互信息作为其对于此类别的权重，权重越大说明该高斯函数对应的~Fisher Vector~对于该行为类别就越重要，而权重小的高斯函数对应的特征应该在多任务学习之后被抛弃。两个类别共同持有的高斯函数的个数用于衡量两个类别之间的相似度。


假设给定数据库中共有~$C$~个行为类别，对于第~$c$~个类，对应的训练数据为~$\{\mathbf{x}_{c,i},y_{c,i}\}_{i=1}^{N_c} \subset \mathbb{R}^{D \times 1}(c = 1,..,C)$~，$i$~和~$N_c$~分别表示第~$c$~个行为类别中训练样本的序号和个数。通过将~$K$~个高斯函数对应的梯度向量串联可将一个样本表示为~$\{\mathbf{x}_{c,i}^{k}\}_{k=1}^K$~，其中~$k$~表示高斯混合模型中高斯函数的序号，$\mathbf{x}_{c,i}^k$~为第~$k$~个高斯函数对应的特征向量。

互信息（Mutual Information，MI）是概率论和信息论中常用的一个量度，它一般用来衡量变量间相互依赖性的程度。在特征选择应用中，互信息被用来衡量某个特征和特定类别的相关性，如果信息量越大，那么特征和这个类别的相关性越大。反之也是成立的。基于此理论基础，为了探求高斯函数与行为类别之间的关系，我们提出了利用互信息来衡量一个高斯函数对于一个行为类别的重要性。具体来说，令~$I_{c,k}(\mathbf{x}_{:}^k,\mathbf{y})$~表示第~$c$~个行为类别和第~$k$~个高斯函数之间的互信息，其中~$\mathbf{x}_{:}^k = \{\{\mathbf{x}_{c,i}^k\}_{i=1}^{N_c}\}_{c=1}^C$~为将数据库的所有视频表示为~Fisher Vector~之后，第~$k$~个高斯函数对应的特征维度组成的矩阵，其中下标~$:$~表示了它包含来自所有样本的特征。$\mathbf{y}$~表示类标空间，互信息的值可由如下公式计算：
\begin{equation}
\label{f25}
I_{c,k}(\mathbf{x}_{:}^k,\mathbf{y}) = H(\mathbf{y}) + H(\mathbf{x}_{:}^k) - H(\mathbf{x}_{:}^k,\mathbf{y}),
\end{equation}
上式中~$H$~表示一个随机变量的熵，是随机变量不确定性的度量。$y$~的值随类别标签~$c$~的值变化而变化。当计算~$I_{c,k}$~时，所有属于第~$c$~个类别的视频样本都是视为正样本，则对应的~$y$~值为~$1$~，而其他不属于第~$c$~个类别的所有样本都视为负样本，$y$~的值为~$-1$~。 这个步骤的处理不仅仅方便了互信息的计算，而且和最终对每个类别训练二元线性分类器的时候是一致的。在最终的多任务学习模型中，在对每个类别训练分类器的时候对类标的处理也是相同的方式。

如果是设$X$是一个取有限个值的离散随机变量，其概率分布为
\begin{equation}
\label{f26}
 P(X=x_i) = p_i,~i = 1,2,..,n.
\end{equation}

则随机变量~$X$~的熵~$H$~通常被如下的公式所计算：
\begin{equation}
\label{f27}
 H(X) = - \sum_i P(x_i)\log_bP(x_i),
\end{equation}
\begin{figure}[t]
\begin{center}
%\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
   \includegraphics[width=1\linewidth]{12.eps}
\end{center}
   \caption{Fisher Vector~中同属于一个高斯函数的特征值直方图}
\label{p14}
\end{figure}
上式中~$b$~表示对数的基数。$H$~只依赖于~$X$~的分布，而与~$X$~的取值无关。在我们的工作中~$X$~表示为~Fisher Vector~。如果要通过计算概率分布函数来求解~$H(\mathbf{x}_{:}^k)$~将会耗费大量的时间和精力，所以我们采取了文献~\citep{ZhangWC14}~的方法，利用了频率来代替概率函数。具体的，我们如公式~\eqref{f28}~所示将~Fisher Vector~的中的值量化为若干个组，为了计算的简单，在我们的实验中我们将组的个数设置为了~2~。 其他的量化方法也是可行的，通过实验我们发现组的个数对实验结果并没有太大的影响。在将视频表示为~Fisher Vector~之后，通过统计每个高斯函数对应的~Fisher Vector~特征值的分布规律，可知~$0$~必须被设为划分组的阈值，具体分布如图~\ref{p14} 所示。
\begin{equation}
\label{f28}
x = \left\{\begin{matrix}
0 & x < 0\\
1& otherwise,
\end{matrix}\right.
\end{equation}
通过对~Fisher Vector~做了量化处理之后，则公式~\eqref{f25}~中的离散熵可以被如下公式所计算：
\begin{equation}
\label{f29}
H(\mathbf{x}_{:}^k) = -\sum_{j=1}^{2}p_j\log_2(p_j),
\end{equation}
上式中~$p_j$~表示的是矩阵~$\mathbf{x}_{:}^k$~中的每一项落入第~$j$~个组的频率。所有的~$p_j$~都是可以通过得到数据库的~Fisher Vector~之后，通过统计其特征值分布统计计算得到的。

在文献~\citep{ZhangWC14}~的工作中，Yu Zhang~等人提出了基于互信息的排序方法，并应用于特征的选择和特征降维。我们的工作和他们尽管都用到了互信息，但是在细节和规划上却有很大的不同。前者仅仅计算了每一单独维度的特征和图像类别之间的互信息，而忽略了每个维度的特征对于不同类别的重要程度不同的事实。我们计算的是一个高斯函数对应的连续维度的特征对于行为类别的互信息， 从而衡量此高斯函数对于类别的重要性。我们的目的是不仅仅可以为每一个行为类别挑选出最具有判别性的特征从而训练出可信赖的二元线性分类器，而且可以通过量化类别持有的高斯函数的个数来衡量类别之间的相似性。从而探索数据库潜藏的类别结构信息。此外，Yu Zhang~将互信息低的特征维度直接抛弃达到特征的选择和降维，而我们利用了多任务学习方法和组结构约束来实现特征选择。

当我们为所有的高斯函数分别计算出它们对于每个行为类别的互信息~$I_{c,k}$~之后，我们用此来衡量高斯函数对于行为类别的重要程度，$I_{c,k}$~ 越大，说明该高斯函数对应的~Fisher Vector~特征维度对于该行为类别越重要。为了衡量行为类别之间的相似性，我们利用阈值~$\lambda$~将正规化之后的互信息矩阵~$\mathbf{I}$~转化为一个值为~0~或者~1~的二元矩阵，具体公式如下所示：
\begin{equation}
\label{f30}
I_{i,j} = \left\{\begin{matrix}
0 & I_{i,j} < \lambda\\
1& otherwise,
\end{matrix}\right.
\end{equation}
$\mathbf{I}\subset\mathbb{R}^{C\times K}$~表示了对于所有行为类别而言高斯函数的重要性权重。上式说明了对于行为类别不重要的特征应该抛弃，重要的应该保留。所以利用阈值~$\lambda$~来量化互信息矩阵~$\mathbf{I}$~。$I_{i,j}$~如果大于~$\lambda$~则令其为~$1$~，说明对于第~$i$~个行为类别，第~$j$~个高斯函数对应的~Fisher Vector~很重要，故予以保留，反之抛弃。如果行为类别同时保留的高斯函数的个数越多，则说明它们之间的相似度越高。

将互信息矩阵~$\mathbf{I}$~转化为二元矩阵之后，就可以基于它来计算相似度矩阵~$\mathbf{S} \subset\mathbb{R}^{C \times C}$~，我们用~$s_{i,j}$~ 来表示第~$i$~个类别和第~$j$~个类别之间的相似度，它可由如下的公式计算：
\begin{equation}
\label{f31}
 s_{i,j}  = \sum(\mathbf{I}_{i} \odot \mathbf{I}_{j}),
\end{equation}
上式中~$\odot$~表示按位与，即将第~$i$~个类别与第~$j$~个类别的高斯权重行向量按位与之后再求和，所得的值正是两个类别同时选择的类别的个数，也就是它们之间的相似度~$s_{i,j}$~。通过计算互信息矩阵~$\mathbf{I}$~中的每两行之间按位与之和后，可以得到一个对称的相似性矩阵~$\mathbf{S}$。

可以发现此相似性度量方法是直接从特征的角度出发，所以它得到的类别之间的相似性关系也是基于特征的。具体而言，相似度矩阵~$\mathbf{S}$~和互信息~$\mathbf{I}$~都是基于通过估计特征~$\mathbf{x}$~的概率分布函数计算得到的。所以如果使用不同的特征描述子，由于它们表示了不同的特征空间和分布，从而可能使得类别之间的相似结构也是不同的。这也是基于互信息相似性度量方法的灵活性和优越性。

\subsection{基于互信息的多任务行为识别}
基于互信息的多任务行为识别方法的具体流程如图~\ref{p13}~所示。通过对~Fisher Vector~向量和数据库中行为类别的观察。我们得到了两个重要假设：（1）Fisher Vector~中的连续维度的特征对应着一个高斯函数，不同的高斯函数捕捉了视频特定的视觉和运动特征，所以高斯函数对于行为类别的重要程度是不同的。（2）数据库中的行为可以分为若干个组，每个组内的任务都是相似的且共享相同的特征空间，即会共享更多的来自于同一个高斯函数的特征维度。基于这两个重要假设，我们首先将视频表示为~Fisher Vector~，然后利用~\ref{431}~小节中的方法通过计算高斯函数对于行为类别的互信息得到类别之间的相似度矩阵~$\mathbf{S}$~。然后和第三章的方法类似，通过反向传播算子聚类法得到基于训练特征的最优的任务结构之后，利用基于组结构约束的多任务学习框架得到分类模型。

具体的目标函数如公式~\eqref{fgroup}~所示，区别在于在本方法中先验结构约束的计算方法是不同的。基于SVM间隔的行为识别利用行为之间的~SVM~间隔来衡量行为之间的相似度，而本方法通过计算高斯函数对于行为类别的互信息得到类别之间的相似度矩阵~$\mathbf{S}$~。

优化求解公式~\eqref{fgroup}~之后，对于新的测试视频，将它表示为~Fisher Vector~~$\mathbf{x}_n \in \mathbb{R}^D$~之后，它对应的标签~$y_n$~ 可由公式~\eqref{fpredict}~求得。

\section{实验结果与分析}
\label{44}
本小节先介绍了实验的具体细节，包括数据库、特征、基准方法和参数。然后展示了基于互信息的多任务行为识别和对比方法分别在行为识别数据库~HMDB51~和~UCF50~上的结果，并给出了结果的分析。
\subsection{实验设计}

本方法的实验步骤与基于~SVM~间隔的行为识别方法的实验步骤非常相似，所以在此不再对特征、基准方法和参数选择上再做赘述，具体可以参照~\ref{331}~小节，下面只简单的对数据库做介绍。

本实验中使用的数据库之一~UCF50~\cite{ReddyS13} 总共高寒~6617~个视频，它们分别来自~50~个行为类别。如图4.3所示所有的视频都来自于~Youtube~。 我们的对于训练数据、验证数据还有测试数据的划分都依照了~\cite{SadanandC12,ZhouWJZ13}~中的步骤。 此外，我们还依照了~\cite{ZhouWJZ13}~的方法，分别用~$25\%$~，$50\%$~，$75\%$~和~$100\%$~的训练数据进行了实验。每次设置下都将实验重复了十次。 ~UCF50~的部分视频样本示例如图~\ref{p14}~所示。

HMDB51数据库在第三种中已做了介绍，除了基本的实验之外，为了展示多任务学习的优点，我们同样随机选择了$10\%$, $20\%$, $30\%$, $40\%$, $50\%$, $60\%$, $70\%$, $80\%$, $90\%$的训练数据进行了实验，如上所述，每次设置下都将实验重复了十次。

我们选择MAP(mean average precision)作为最终的评估参数。
\begin{figure*}
\begin{center}
\includegraphics[width=0.8\linewidth]{ucf50.eps}
\end{center}
\caption{UCF50中的样本示例。}
\label{p14}
\end{figure*}

\subsection{实验结果与分析}


首先如表4.1所示，我们比较了基于互信息的多任务行为识别与三个基准方法的识别精度。从表中的结果可以看出，基于互信息的多任务行为识别不管是利用哪个类型的描述子，与基准方法相比识别精度都是最高的。我们的多任务学习框架利用了组结构约束，它综合了$\ell_{1}$ 范数和$\ell_{21}$范数的优点。当所有的行为类别都属于同一个组的时候，也就是所有的类别都相似的情况下，公式\eqref{f18} 中的结构正则项退化为$\ell_{21}$ 范数。当所有的行为类别都自成一组时，也就是所有的类别之间都不共享特征的情况下，结构正则项退化为$\ell_{1}$范数。


\begin{table}
\begin{center}
\begin{tabular}{|p{1.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|}
\hline
特征/方法 & \tabincell{c}{多任务行为识别}& \tabincell{c}{基于$\ell_1$范数的 \\ 多任务行为识别} &\tabincell{c}{基于$\ell_{21}$范数的 \\ 多任务行为识别}  & \tabincell{c}{基于互信息的\\ 多任务行为识别} \\
\hline
HOG & 40.22 & 44.05 & 43.84 & \textbf{45.92} \\
\hline
HOF & 49.00 & 50.04 & 50.09 & \textbf{50.98} \\
\hline
MBHx & 40.24 & 42.81 & 42.61 & \textbf{44.03} \\
\hline
MBHy & 47.13 & 48.60 & 48.62 & \textbf{49.57} \\
\hline
combined & 60.15 & 60.38 & 60.31 & \textbf{60.84} \\
\hline
\end{tabular}
\end{center}
\caption{基于互信息的多任务行为识别与基准方法在HMDB51上的实验结果对比。}
\end{table}


\begin{table*}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Percentage& 10$\%$ & 20$\%$ & 30$\%$ & 40$\%$ & 50$\%$ \\
\hline
Single Task&36.17 $\pm$ 1.79& 45.45 $\pm$ 1.30&50.39 $\pm$ 1.15 &53.17 $\pm$ 0.88 &54.72 $\pm$ 0.71\\
Proposed Work&40.03 $\pm$ 2.11 &48.10 $\pm$ 1.75&52.39 $\pm$ 1.43 &55.03 $\pm$ 1.12&56.53 $\pm$ 0.94\\
\hline\hline
Percentage& 60$\%$ & 70$\%$ & 80$\%$ & 90$\%$ &100$\%$ \\
\hline
Single Task&56.45 $\pm$ 0.73&57.68 $\pm$ 0.53& 58.61 $\pm$ 0.65 & 59.54 $\pm$ 0.40 &60.22\\
Proposed Work&57.20 $\pm$ 0.88 & 59.15 $\pm$ 0.81& 59.48$\pm$ 0.73&60.14 $\pm$ 0.52 &60.84\\
\hline
\end{tabular}
\end{center}
\caption{基于互信息的多任务行为识别和单任务学习在训练样本变化时在HMDB51数据库的实验结果对比，该实验中用的特征为四种描述子的串联向量。}
\end{table*}

基于互信息的多任务行为识别和单任务学习在训练样本变化时的实验结果如表4.2所示。很明显，当训练数据较少的时候多任务学习与单任务学习相比得到了很大的提升。这个提升是由于多任务学习的特征共享机制导致了。这个结果也说明了我们关于数据库中的行为可以分为若干个组，每个组内的任务都是相似的且共享相同的特征空间这个假设的正确性。


最后我们把基于互信息的多任务行为识别和行为识别领域一些先进的方法在HMDB51数据库上做了对比试验。如表3.2所示，基于SVM间隔的多任务行为识别甚至比基于深度学习的方法\cite{SimonyanZ14}效果还要好。

\begin{table*}
\begin{center}
\begin{tabular}{|p{7cm}<{\centering}|p{3cm}<{\centering}|}
\hline
方法& 精度 \\
\hline
Sadanand and J.Corso~\cite{SadanandC12} & $26.9 \%$ \\
\hline
Yang et al.~\cite{YangT14} & $53.9 \%$\\
\hline
Hou et al.~\cite{HouZSS14} & $57.88 \%$ \\
\hline
K. Simonyan and A. Zisserman~\cite{SimonyanZ14} & $59.5 \%$ \\
\hline
基于互信息的多任务行为识别  & $\textbf{60.84} \%$ \\
\hline
\end{tabular}
\end{center}
\caption{基于互信息的多任务行为识别方法与行为识别领域一些先进方法在HMDB51上的实验结果对比。}
\end{table*}


\begin{figure*}
\begin{minipage}[t]{0.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{smatrix.eps}
\label{fig:side:a}
\end{minipage}%
\begin{minipage}[t]{0.5\textwidth}
\centering
\includegraphics[width=0.97\linewidth]{cmatrix.eps}
\label{fig:side:b}
\end{minipage}
   \caption{\textbf{Left: }在UCF50数据库上，基于HOG特征训练计算得到的互信息矩阵$I$的一部分。行和列分别表示了行为类别和高斯函数。矩阵$I$中颜色的深浅代表了对应高斯函数对于行为类别的重要程度。 \textbf{Right: }通过$I$计算得到的相似度矩阵$S$。白色表示0。}
\end{figure*}

然后我们在UCF50上进行了实验对比。如图4.5所示，我们展示了一部分在UCF50数据库上，基于HOG特征训练计算得到的互信息矩阵$I$和它对应的相似度矩阵$S$。在相似性矩阵$I$中，行代表了行为类别，列代表了高斯函数。$I_{i,j}$的深浅表示了对于第$i$个行为类别而言，第$j$个高斯函数的重要程度。通过对$I$进行公式~\eqref{f30}的处理得到矩阵$S$，$s_{i,j}$是白色表示对于第$i$ 个类而言，第$j$个高斯函数对应的特征维度不太重要，所以抛弃它。从图4.5中很容易可以观察到，同属于一组的行为类别更容易同时和一个高斯函数具有更密切的关系。当然$S$ 和$I$也存在一些异常任务，这说明了组结构约束只是一个软约束，它非常的灵活。

\begin{table}
\begin{center}
\begin{tabular}{|p{1.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|}
\hline
特征/方法 & \tabincell{c}{多任务行为识别}& \tabincell{c}{基于$\ell_1$范数的 \\ 多任务行为识别} &\tabincell{c}{基于$\ell_{21}$范数的 \\ 多任务行为识别}  & \tabincell{c}{基于互信息的\\ 多任务行为识别} \\
\hline
HOG&82.37&83.4&83.42&\textbf{84.04}\\
\hline
HOF&85.69&87.69&86.89&\textbf{87.98}\\
\hline
MBHx&83.18&83.94&84.03&\textbf{84.54}\\
\hline
MBHy&85.97&87.08&86.82&\textbf{88.02}\\
\hline
combined&88.13&88.69&88.54&\textbf{89.17 }\\
\hline
\end{tabular}
\end{center}
\caption{基于互信息的多任务行为识别与基准方法在UCF50上的实验结果对比。}
\end{table}

如表4.4所示，我们在数据库UCF50上比较了基于互信息的多任务行为识别与三个基准方法的识别精度。从表中的结果可以看出，基于互信息的多任务行为识别不管是利用哪个类型的描述子，与基准方法相比识别精度都是最高的。这个结果和我们在HMDB51上的结果一致，原因也是如上文中分析的：我们的多任务学习框架利用了组结构约束，它综合了$\ell_{1}$ 范数和$\ell_{21}$ 范数的优点。图4.4展示了当仅使用25 $\%$的训练数据时，基于互信息的多任务行为识别方法在UCF50行为数据库中的绝大多数类别上的识别精度的提升。值得注意的是，同属于一组的行为类别普遍获得了显著的识别精度上的提升，，这都归功于多任务学习框架利用了原本被忽略了类别之间的信息。
\begin{figure*}
\begin{center}
%\fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
\includegraphics[width=1\linewidth]{ucf501.eps}
\end{center}
\caption{当仅使用25 $\%$的训练数据时，基于互信息的多任务行为识别方法在UCF50行为数据库中的绝大多数类别上的识别精度的提升。}
\label{fig:short}
\end{figure*}

\begin{table*}
\begin{center}
\begin{tabular}{|c|c|}
\hline
Methods & Accuracy\\
\hline
Sadanand and J.Corso~\cite{SadanandC12} & 57.9 $\%$ \\
\hline
Kishore K. Reddy and Mubarak Shah~\cite{ReddyS13} & 76.9$\%$\\
\hline
Zhou et al.~\cite{ZhouWJZ13}& 78.3$\%$\\
\hline
Wang et al.~\cite{Wang2013} & 85.9$\%$\\
\hline
Proposed Method & \textbf{89.2}$\%$\\
\hline
\end{tabular}
\end{center}
\caption{基于互信息的多任务行为识别与基准方法在UCF50上的实验结果对比。}
\end{table*}

在表4.5中，我们把基于互信息的多任务行为识别和行为识别领域一些先进的方法在UCF50数据库上做了对比试验。在这些方法中，Qiang Zhou~\cite{ZhouWJZ13}等人的工作和我们提出的方法略为相似。他们的工作本文在2.3.2小节中已做了简单的介绍。Qiang Zhou提出了一种基于多任务学习框架的行为识别方法，他们认为任务之间分享的基任务可以视为不同的行为类别之间共享的运动元素。比如跑步、走路、挥手等运动其实都是有身体部位的基本移动构成的。最终每个类别的分类器参数由基本运动元素的线性组合而成。和他们的工作相比，我们的方法首先认为行为类别之间共享的是确切对应着同一个高斯函数的的连续维度的特征，其次我们通过互信息来寻找潜藏在数据库中的行为结构，最后在Qiang Zhou的工作中共有3个参数需要调节，而且基任务的个数需要事先确定，而基于互信息的多任务行为识别的方法参数的个数比较少，而且由于反向传播算子聚类法的使用，行为可分为的组的个数也不用事先确定。

\section{本章小结}
\label{45}
在第三章中提出的基于SVM间隔的多任务学习方法通过利用SVM间隔计算行为类别的相似性矩阵，然后聚类得到数据库的潜在的类别结构，最后将此结构作为先验约束与多任务学习框架结合，通过利用任务之间的相关信息提高分类模型的性能和泛化能力。本文通过观察常用特征Fisher Vector，得到了以下假设：（1）Fisher Vector中的连续维度的特征对应着一个高斯函数，不同的高斯函数捕捉了视频特定的视觉和运动特征，所以高斯函数对于行为类别的重要程度是不同的。（2）数据库中的行为可以分为若干个组，每个组内的任务都是相似的且共享相同的特征空间，即会共享更多的来自于同一个高斯函数的特征维度。基于这两个假设，本文基于SVM间隔的多任务行为识别方法提出了一种新的用来衡量行为类别之间相似度的方法，即基于互信息的相似性度量。通过计算出每个高斯函数对于每一个行为类别的互信息来衡量其对这个类别的重要性。得到数据库的相似性矩阵之后，利用反向传播算子聚类法得到类别中潜在的结构关系。基于互信息的多任务行为识别方法可以鼓励同属于一组的任务共享了来自于一个高斯函数对应的特征，它直接从特征的角度来计算行为类比的相似性，与基于SVM间隔的多任务行为识别相比更加的直观，计算也更加的简单。在数据库HMDB51和数据库UCF50上的实验实验结果都表明基于互信息的多任务行为识别较之其他的多任务行为识别方法的优越性。


