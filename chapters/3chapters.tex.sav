
\chapter{基于SVM间隔的多任务行为识别}

\section{引言}
随着计算机网络不断发展和Youtube、优酷土豆等视频社交网站的飞速普及，视频数据已逐渐成为人们获取信息的主要涟源。视频的种类和内容越来越丰富，在日常生活中的应用也越来越广泛。视频与图片等其他媒体介质相比，首先获取成本相似，且信息传播的效率更高，内容也更丰富。对视频中的行为进行识别具有极大的理论研究价值及广阔的应用市场，比如智能人机交互和视频监控，不仅如此它还可以作为其他应用的基础，比如通过视频中的行为识别可以提高基于内容的视频检测的准确度。如第一章所述，行为识别实际上是一个分类问题，目前现存的行为识别方法的一般流程都是提取视频特征再利用特征训练分类器。然而目前的方法把每一个行为类别当做了一个任务，对每个任务学习模型的过程是独立的，从而忽略了任务之间的信息。如果利用行为类别之间的信息，提高行为识别的性能是本文的研究重点。


本论文通过观察发现数据库中的行为类别存在潜在的结构信息，如图1.2所示，在HMDB51数据库中的行为咀嚼和吃饭非常相似，所以它们同属于一组且分享特征，反之咀嚼和骑马不属于同一组所以不共享特征信息。本论文基于这个观察并针对现存方法不能有效利用行为类别之间信息的不足，提出了利用基于组约束的多任务学习框架来识别行为。具体的流程框架如图3.1 所示，首先对数据库中的所有任务两两训练1对1的SVM，如果数据库中共有$n$个种类，即训练$C_n^2$个SVMs，然后用SVM的间隔作为对应的两个类别之间的相似性度量，利用反向传播算子法对相似度矩阵进行聚类，可以得到数据库的潜在的类别结构，最后将此结构作为先验约束，简历目标函数，求解优化得到所有任务对应的分类参数，完成行为的识别。

本章提出了一种基于SVM间隔的多任务行为识别方法，主要内容安排如下：在3.2节中介绍任务之间的相似性距离和任务潜在结构的计算方法；在3.3节中介绍目标函数和优化；在3.4 节中进行实验仿真并对实验结果进行分析；在3.5节中对本章内容进行总结。

\begin{figure*}
\begin{center}
\includegraphics[width=1\linewidth]{framework1.eps}
\end{center}
\caption{基于SVM间隔的多任务行为识别的主要流程。}
\label{fig:short}
\end{figure*}

\section{任务潜在结构学习}

\subsection{SVM间隔}

支持向量机（support vector machines, SVM）是一种二类分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器。Cortes与Vapnik提出了线性支持向量机，Boser、Guyon与Vapnik又引入了核技巧，提出了非线性的支持向量机。当输入空间为欧式空间与离散集合、特征空间为希尔伯特空间时，核函数表示将输入到输入空间映射到特征空间得到的特征向量之间的内积。通过使用核函数可以学习非线性支持向量机。一个线性的支持向量机的目的是从$n$维的特征空间中找到一个超平面，如图3.2所示，该超平面可以表示为：
\begin{equation}
\label{f9}
  w^Tx + b = 0.
\end{equation}

一个超平面在二维空间中就是一个条直线，SVM希望通过这条直线可以将两类数据分割开来，具体来说SVM通过求解优化得到$w$和$b$，令$f(x) = w^Tx + b$，要求所有在直线$w^Tx + b = 0$一侧的样本对应的标签为$1$，另一端的样本标签为$-1$。如图3.2所示，两种颜色的点分别表示两个种类，红颜色的线表示一个可行的超平面，每个样本点据超平面的距离可以表示它分类正确的确信度。即越接近超平面的点越不容易被分类，反之，据超平面很远的点则很容易分辨出其类别。可以看出具有将这两种数据线性分类的超平面很多，SVM 定义了可以使分类间隔最大的超平面即为最好的超平面。对于给定的训练数据集$T$和超平面$w^Tx + b = 0$，定义超平面$(w,b)$关于样本点$(x_i,y_i)$的函数间隔为：
\begin{equation}
\label{f10}
\hat{\gamma_i} = y_i(w^Tx_i + b),
\end{equation}
定义超平面$(w,b)$关于训练数据集$T$的函数间隔为超平面$(w,b)$关于$T$中所有样本点$(x_i,y_i)$的函数间隔之最小值，即

\begin{equation}
\label{f11}
\hat{\gamma} = \min_{i = 1,...,N}\hat{\gamma_i}.
\end{equation}

函数间隔可以表示分类预测的正确性及确信度。但是在选择超平面时，仅仅有函数间隔还是不够的。因为如果成比例的改变$w$和$b$，例如将它们改为$3w$和$3b$，超平面其实并没有改变，但是函数间隔却变成了原来的3倍。为了避免这一事实，可以通过对超平面的法向量$w$加一些规范化的约束，例如限制$\parallel w\parallel = 1$，使得无论$w$和$b$ 无论怎么变化，间隔都是不变的。这是函数间隔变成了几何间隔。具体来说超平面$(w,b)$ 关于样本点$(x_i,y_i)$的几何间隔为
\begin{equation}
\label{f12}
\hat{\gamma_i} = y_i(\frac{w^T}{\parallel w\parallel}x_i + \frac{b}{\parallel w\parallel}),
\end{equation}
定义超平面$(w,b)$关于训练数据集$T$的函数间隔为超平面$(w,b)$关于$T$中所有样本点$(x_i,y_i)$的几何间隔之最小值，即

\begin{equation}
\label{f13}
\gamma = \min_{i = 1,...,N}\gamma_i.
\end{equation}

支持向量机学习的基本思想是求解能够正确划分训练数据集并且几何间隔最大的分离超平面。对于线性可分的训练数据集而言，可以线性分割数据的超平面有无穷个，但是几何间隔最大的超平面时唯一的，它不仅仅可以把正负实例点分开，而且对于离超平面最大的点，也就是最难分的实例点也有足够大的确信度将它们分开，这样的超平面对于未知标签的测试用例有较好的分类预测能力，具体的损失函数如下所示：
\begin{equation}
\begin{aligned}
\label{f14}
&\min_{w,b} \frac{1}{2}\parallel w\parallel^2 \\
&s.t. y_i(w^Tx_i + b - 1) \geq 0, i = 1, 2,...,N
\end{aligned}
\end{equation}

\begin{figure*}
\begin{center}
\includegraphics[width=0.6\linewidth]{10.eps}
\end{center}
\caption{最大几何间隔分类超平面示例，据超平面（红色线）最近的样本点称为支持向量。}
\label{fig:short}
\end{figure*}

在线性可分的情况下，训练数据集的样本点中与超平面最近的样本点即为支持向量。用数学的语言来讲的话，支持向量是令公式\eqref{f14}成立的样本点，即满足

\begin{equation}
\begin{aligned}
\label{f15}
 y_i(w^Tx_i + b - 1) = 0
\end{aligned}
\end{equation}

如图3.2所示，对于$y_i = 1$的样本点，支持向量在超平面$H_1:w^Tx+b=1$上，对于$y_i = -1$的样本点，支持向量在超平面$H_2:w^Tx+b = -1$上。在$H_1$和$H_2$上的点就是支持向量。

注意到$H_1$和$H_2$平行，并且没有样本点落在这两条直线之间，$H_1$和$H_2$之间的距离称为间隔。间隔的大小依赖于超平面的法向量$w$，等于$\frac{2}{\parallel w\parallel}$。$H_1$和$H_2$称为间隔边界。

在决定超平面时只有作为支持向量的样本点才起作用，而其他样本点并没有帮助。如果移动支持向量将改变所有得的超平面，但是如果在间隔边界以外移动其他任意样本点，甚至去掉或者添加新的样本点，也对最优超平面不起任何影响。支持向量机名字的由来也是因为支持向量在确定超平面时起着决定性的作用。如果两个类别的差异性很大，很好被区分，那么由训练样本训练得到的支持向量机的间隔必定也很大，反之如果两个类别非常相似，那么得到的支持向量机的间隔也会很小。所以可以用支持向量机的间隔来衡量两个类别之间的相似度。

\subsection{基于SVM间隔的相似性度量}
由上文所述，无论是真实世界还是数据库中，不同的行为类别之间都是有关系的。进一步通过观察发现行为识别的数据库中的行为类别存在潜在的结构信息，具体来说我们认为数据库中行为可以分为几个组，相似的行为类别同属于一组且分享特征，反之不属于于同一组的类别所以不共享特征信息。于是本文采用了SVM间隔作为类别之间的相似性度量，通过计算所有类别之间的相似度矩阵再通过聚类得到类别之间潜在的数据结构。

为了将数据库中任意两个行为类别的相似程度量化，我们利用相对应的视频数据对每对行为类别训练$1-vs-1$的SVM。正如上一个小节中提到的，两种行为如果越相似，那么它们对应的SVM间隔就会越小，说明它们越难分开。我们设$s_{c_p,c_q}$为类别$p$和$q$之间的相似度，则$s_{c_i,c_j}$的具体计算公式如下:
\begin{equation}
\label{f16}
s_{c_p,c_q} = \sum_{\forall(i,j)\in c_p\cup c_q}\alpha_i \alpha_j(-1)^{I[c(i),c(j)]}K(x_{p,i}
,x_{q,i}),
\end{equation}
上式中，$i$和$j$表示来自第$p$个类别和第$q$个类别交集的两个样本序号。$x_{p,i}$表示来自第$p$个类别的第$i$个样本。$\alpha$表示支持向量的系数。$\alpha$可以通过训练SVM时通过求解最优超平面的时候得到，每一个训练样本都有一个对应的$\alpha$值，只是仅仅当这个训练样本是支持向量时$\alpha$的值不为$0$。$c(\dot)$可以返回给定样本的类标序号。$I[\dot]$也是一个函数，它的具体形式如下：

\begin{equation}
\label{f17}
I[c(i),c(j)] = \left\{\begin{matrix}
0 & otherwise \\
1& c[i] \neq c[j],
\end{matrix}\right.
\end{equation}
当样本$i$和$j$具有相同的类标时，$I[c(i),c(j)]$的值为0，因为我们要计算的是两个类别之间的相似度，当$i$和$j$来自同一个类的时候是没有意义的。

$K(\dot,\dot)$是核函数。核函数在线性模型不可分的情况下可以通过一个非线性变换将输入空间映射到一个线性可分的高维空间，从而在高维的空间中解决问题。核函数有很多的种类，常用的有多项式核函数（polynomial kernel function)、高斯核函数（Gaussian kernel function)和线性核函数等。在公式\eqref{f16}中，核函数的选择应该视特征的种类而定。在本文中我们使用的特征为Fisher Vector，所以核函数为线性核函数。而且由于每个$1-vs-1$SVM只需要用到两个类别对应的训练样本，所以即使总共需要训练$\binom{2}{C}$个分类器，但是速度还是很快的。

通过对数据库中的每对类别训练$1$-vs-$1$SVM并计算根据公式\eqref{f16}，最终可以得到数据库中所有类别对应的相似度矩阵$S \in \mathrm{R}^(C \times C)$，这是一个对称矩阵，且$s_{p, q}$代表了第$p$个类别和第$q$类别的相似度，$s_{p, q}$越小，说明这两个类越相似，反之亦然。得到相似度矩阵$S$之后，我们利用反向传播算子聚类法（Affinity Propagation Clustering）得到了数据库中隐含的类别的结构信息。值得注意的是，我们不需要提前决定聚类结构中簇的数量，它可以基于相似度矩阵$S$被聚类算法所决定。这么做的原因有两点，首先凭肉眼或者人工的感觉来判断行为类别相似是不准确的，视觉信息不相似的行为类别有时也会共享相似的运动轨迹等特征。所以人工的判断数据库中行为组的个数是不准确的，不仅如此，工作量还非常的大。此外，根据公式\eqref{f16} 可以看出类别之间相似性的度量是基于特征计算的。具体来说，对于不同的特征e.g., Histograms of Oriented Gradients (HOG) and Histograms of Optical Flow (HOF))，得到的SVMs和相似度矩阵$S$也是不同的，那么随之对应的类别的组结构也是不同的。总而言之，对于一个行为识别数据库并不存在一个最优的组结构，组的个数和每个组内具体的行为类别是随特征类型的变化而变化的。

在Hou Rui\cite{HouZSS14}的工作中，也利用到了基于SVM间隔的相似性度量。但是与他们工作相比，我们的方法在应用和构造上都有所创新改变。Hou Rui通过计算SVM间隔来找到每个类别的相似类别，从而可以学习到高级语义上的判别性特征。然而我们通过计算基于SVM间隔的相似度来探索潜藏在数据库中的类别结构信息，从而可以用其约束多任务学习鼓励同一个组内的类别共享特征信息。

\section{基于SVM间隔的多任务行为识别}

基于SVM间隔的多任务行为识别的具体流程如图3.1所示。如果将数据库中的行为类别视为任务，通过观察我们发现这些任务之间是有关系的。而且我们假设任务存在潜在的结构信息，即任务可以分为若干个组，每个组内的任务都是相似的且共享相同的特征空间，不同组内的任务进行特征排斥和竞争。为了求得任务的结构信息，我们通过对每对任务训练$1-vs-1$的svm，利用公式\eqref{f16}求得每对任务之间的相似性距离，得到相似性矩阵$S$，然后通过反向传播算子聚类法得到基于训练特征的最优的任务结构。我们把该结构作为先验信息，利用基于组结构约束的多任务学习框架同时学习每个任务对应的二元线性分类器。

假设在给定行为数据库中共有$C$类行为类别。对于第$c$类别，对应的训练样本为 $\{x_{c,i},y_{c,i}\}_{i=1}^{N_c} \subset \mathrm{R}^{D \times 1}(c=1,...,C)$，其中$i$ 表示第$c$ 个类别的视频样本的序号，$N_c$表示属于第$c$个类别的样本总量。$x_{p,i}$表示来自第$p$个类别的第$i$个样本的$D$维特征，$y_{c,i}$为其对应的标签。且假设通过聚类之后可将任务总共分为$L$组。则具体的目标函数如下：
\begin{equation}
\label{fl8}
\min_W \sum_{c=1}^C \sum_{i=1}^{N_c} \frac{1}{2} \left[ \max(0,1-y_{c,i}w_c x_{c,i}) \right] ^2 + \lambda_1\sum_{d=1}^D \sum_{l=1}^{L}\Vert w^{d,g_l} \Vert _2+\lambda_2\Vert W\Vert _F^2,
\end{equation}
上式中的第一项为铰链损失函数（hinge loss function）。$W\in\mathrm{R}^{N \times D}$表示所有任务对应的二元线性分类器的参数矩阵，$w_c \in \mathrm{R}^D$表示第$c$ 个任务的参数。第二项为基于组结构的正则项，其中$w^{d,g_l}$是一个行向量，它表示属于第$g_l$个组的所有任务对应第$d$维特征的权重参数。基于组结构的正则项同时利用了$\ell_1$范数和$\ell_{2,1}$范数的优点，从而鼓励组内的特征共享和组间的特征竞争。最后一项为F范数（Frobenius norm）可以防止分类矩阵$W$过拟合。$\lambda_1$和$\lambda_2$是用来控制稀疏与分类损失函数之间的平衡因子。

很明显可以看出，用以约束公式\eqref{f18}的组结构正则项$\sum_{d=1}^D \sum_{l=1}^{L}\Vert w^{d,g_l} \Vert _2$是一个混合范数正则项。尽管它是凸的，但是它优化起来却非平稳

优化求解公式\eqref{f18}之后可以得到每一个行为类别对应的二元线性分类参数$w_c$。 这时对于一个新的测试视频，首先先提取对它提取特征，将它表示为$x_n \in \mathbf{R}^D$，它对应的标签$y_n$可由以下的公式得到：

\begin{equation}
\label{fl9}
y_n = \arg \max_c w_c x_n.?
\end{equation}

Dinesh Jayaraman\cite{JayaramanSG14}等也利用了基于组结构约束的多任务行为，他通过将属性视为任务来同时对每个属性学习分类模型。基于SVM间隔的多任务行为识别方法与他们的工作对比，有如下不同之处：（1）首先前者中任务的组结构是人工分割的。Dinesh Jayaraman通过将描述同类事物的属性分为一组，例如例如描述颜色的属性同属一组，它们之间共享描述颜色的特征。这种做法先验假设太强，而且可能忽视任务之间潜藏的肉眼不可见的信息，所以我们的方法提出了利用任务之间的SVM间隔来衡量任务之间的相似度。（2）我们的方法利用了$\ell_2$范数来防止分类矩阵过拟合，提高了模型的泛化能力。

\section{实验结果与分析}

本小节先介绍了实验中所用数据库、特征、基准方法和参数选择等细节。然后展示了基于SVM间隔的多任务行为识别和对比方法分别在行为识别数据库HMDB51的结果，并给出了结果的分析。
\subsection{实验设计}

为了证明基于SVM间隔的多任务行为识别方法是有效的，我们将在行为识别数据库HMDB51\cite{Kuehne11}上与多种基准方法与目前行为识别领域最先进的一些方法做对比，下面将依次介绍数据库、特征、参数和基准方法。

HMDB51数据库中总共包含6766个视频，它们分别来自51个行为类别，且平均每个类别包含100个以上的视频样本。如图3.3所示所有的样本都是在真实环境下拍摄而得的，比如电影、视频网站等。由于视角、尺寸、背景和光照等因素，HMDB51中即使属于同一类的视频差别也非常大。HMDB51对于行为识别应用而言，是个非常困难的数据库。在数据库的主页上提供了三种训练集和测试集的分割方法，我们的实验也建立在这三种数据分割方法之上，并且最终给出了平均分类精度。

\begin{figure*}
\begin{center}
\includegraphics[width=0.8\linewidth]{11.eps}
\end{center}
\caption{HMDB51中的样本示例。}
\label{fig:short}
\end{figure*}

在我们的实验中，我们利用了improved dense trajectories\cite{Wang2013}来提取局部描述子。首先在连续帧中跟踪兴趣点，然后在轨迹的附近的范围提取HOG、HOF、MBHx和MBHy 四种类型的描述子。和\cite{ WangUKLS09}中的步骤一样，我们首先利用PCA将每种描述子的维度降到一半。然后随机选取256000个特征，通过EM算法学习到由512个高斯组成的高斯混合模型，从而将描述子转化为Fisher Vector的形式。然后对Fisher Vector进行白化、$L_2$正规化和intra正规化之后，得到了最终的特征。在我们的实验中，分别给出了四种类型的描述子单独训练的情况，也给出了将这四种特征串联起来的情况。

在公式\eqref{f18}中的$\lambda1$和$\lambda2$的最优值通过交叉验证选出。而数据库的类别组的最优个数由反向传播算子根据不同的特征得到。

我们提出了3种基准方法，分别为不加正则项的多任务行为识别，基于$\ell_{1}$范数的多任务行为识别，基于$\ell_{21}$范数的多任务行为识别。在所有的多任务行为识别方法中，我们选择Hinge loss作为损失函数。

\subsection{实验结果}

首先我们得到了当四种特征串联时，通反向传播算子聚类方法将51个行为类别划分为了7个组，具体结构为组1: \textit{turn, walk, shake hands, hug and kiss.} 组2: \textit{brush hair, clap, wave, shoot gun, draw sword, sword, climb, climb stairs, drink, eat, pick, sit, stand, pour, shoot bow and pullup.} 组3: \textit{chew, smile, laugh, smoke and talk.} 组4: \textit{push up and sit up.} 组5: \textit{cartwheel, flic flac, hand stand, somersault, push, ride bike and ride horse.} 组6: \textit{catch, hit, swing baseball, throw, dive, fall floor, jump, run, kick ball, fencing, kick, sword exercise and punch.} 组7: \textit{dribble, shoot ball and golf.} 通过这个结果可以看出在视觉和行为轨迹上相似的行为都被分到了一组。比如，行为 chew, smile, laugh, smoke and talk 这些描述面部的微小特征的行为被分到了同一组。

然后我们比较了基于SVM间隔的多任务行为识别和基准方法在HMDB51上的识别精度，具体结果如表3.1所示。通过结果可以看出基于SVM间隔的多任务行为识别无论用哪种类型的特征，效果都比其它的多任务学习框架要好。当所有的行为类别都属于同一个组的时候，也就是所有的类别都相似的情况下，公式\eqref{f18}中的结构正则项退化为$\ell_{21}$范数。当所有的行为类别都自成一组时，也就是所有的类别之间都不共享特征的情况下，结构正则项退化为$\ell_{1}$范数。所以组结构约束综合了$\ell_{1}$范数和$
ell_{21}$范数的优点。

最后我们把基于SVM间隔的多任务行为识别和行为识别领域一些先进的方法在HMDB51数据库上做了对比试验。如表3.2所示，基于SVM间隔的多任务行为识别甚至比基于深度学习的方法\cite{SimonyanZ14}效果还要好。
\newcommand{\tabincelll}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\begin{table}
\begin{center}
\begin{tabular}{|p{1.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|}
\hline
特征/方法 & \tabincell{c}{多任务行为识别}& \tabincell{c}{基于$\ell_1$范数的 \\ 多任务行为识别} &\tabincell{c}{基于$\ell_{21}$范数的 \\ 多任务行为识别}  & \tabincell{c}{基于SVM间隔\\ 多任务行为识别} \\
\hline
HOG & 40.22 & 44.05 & 43.84 & \textbf{44.54} \\
\hline
HOF & 49.00 & 50.04 & 50.09 & \textbf{50.62} \\
\hline
MBHx & 40.24 & 42.81 & 42.61 & \textbf{44.09} \\
\hline
MBHy & 47.13 & 48.60 & 48.62 & \textbf{49.01} \\
\hline
combined & 60.15 & 60.38 & 60.31 & \textbf{60.54} \\
\hline
\end{tabular}
\end{center}
\caption{基于SVM间隔的多任务学习与基准方法在HMDB51上的实验结果对比。}
\end{table}


\begin{table*}
\begin{center}
\begin{tabular}{|p{7cm}<{\centering}|p{3cm}<{\centering}|}
\hline
Methods & Accuracy \\
\hline
Sadanand and J.Corso~\cite{SadanandC12} & $26.9 \%$ \\
\hline
Yang et al.~\cite{YangT14} & $53.9 \%$\\
\hline
Hou et al.~\cite{HouZSS14} & $57.88 \%$ \\
\hline
K. Simonyan and A. Zisserman~\cite{SimonyanZ14} & $59.5 \%$ \\
\hline
基于SVM间隔多任务行为识别  & $\textbf{60.54} \%$ \\
\hline
\end{tabular}
\end{center}
\caption{Comparison of the baselines with our method on the HMDB51 dataset.}
\end{table*}

\section{本章小结}

之前绝大部分的人体行为识别方法都将行为类别当做了独立的任务，分别为每个类别训练其对应分类器。然而通过观察可以发现无论是在数据库中还是在现实生活中，类别之间都是有关系的。相似的类别之间分享相同的视觉信息特征和运动轨迹特征。所以独立为每个类别训练分类器会浪费掉它们之间共享的信息。另一方面，仅有的几种多任务行为识别方法认为所有行为之间都共享同一个特征空间，这个假设对绝大部分情况都不太现实，可能会导致“负迁移”损害模型性能。通过观察可以发现，数据库中的行为类别的关系有亲疏之分，相似程度高的行为可以分为一组，共享相同的特征空间。本章的研究的重点在于挖掘数据库中行为类别之间潜在的结构关系，提出了基于SVM间隔的多任务行为识别。具体来说，首先对于数据库中的每对行为训练一个$1-vs-1$的SVM，通过利用得到的支持向量等结果计算两个行为之间的SVM间隔，并用其来衡量行为之间的相似度。SVM间隔越小，说明行为之间相似度越高，分享的共同信息越多，反之亦然。随后将所有类别对应的相似度矩阵利用反向传播算子聚类法可以得到类别中潜在的结构关系。通过将此结构关系作为先验正则项与多任务学习框架结合，可以鼓励存在于一组内的行为类别共享特征，而不在一组内的行为类别之间进行特征竞争。通过在HMDB51数据库上进行实验，可以表明基于SVM间隔的多任务行为识别较之其他的多任务行为识别方法的优越性，不仅仅如此，本章的方法与行为识别领域一些先进的方法比较也有了性能上的提高。这都表明了，利用行为类别之间的信息，寻找行为类别之间潜在的行为结构是必要的。
