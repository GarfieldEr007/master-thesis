
\chapter{基于SVM的多任务行为识别}
\label{3}
\section{引言}
随着计算机网络不断发展和~YouTube、秒拍等视频社交应用的飞速普及，视频数据已逐渐成为人们获取信息的主要载体。视频数目飞快增长的同时，其包含的内容也愈加丰富。视频与其他媒体介质相比，不仅获取成本相似，而且在信息传播的深度和广度上都更有优势。在这种背景之下，对视频中的行为进行识别具有极大的理论研究价值及广阔的应用市场。如第\ref{1}章所述，行为识别实际上是一个分类问题，现有行为识别方法的一般流程都是先从视频中提取可以表示人体行为的特征，然后利用特征训练分类器。然而目前的方法将每一个行为类别视为一个任务，对每个任务学习模型的过程是独立的，从而忽略了任务之间的信息。如何利用行为类别之间的信息，提高行为识别的性能是本文的研究重点。


本论文通过观察发现数据库中的行为类别存在潜在的结构信息，如图~\ref{p2}~所示，在~HMDB51~数据库中的行为咀嚼（chew）和吃饭（eat）非常相似，所以它们同属于一组且分享特征，反之咀嚼和骑马（ride  horse）不属于同一组所以不共享特征信息。本论文基于这个观察并针对现存方法不能有效利用行为类别之间信息的不足，提出了利用基于组约束的多任务学习框架来实现行为的识别。具体的流程框架如图~\ref{p10}~所示，首先对数据库中的所有任务两两训练~1-VS-1~的~SVM，如果数据库中共有~$n$~个种类，即总共训练~$C_n^2$~个~SVMs，然后用支持向量之间的间隔来度量对应的两个类别之间的相似程度，对相似度矩阵进行聚类可以得到数据库的潜在类别结构，最后将此结构作为先验约束，建立目标函数，求解优化得到所有任务对应的分类参数，完成行为的识别。

本章提出了一种基于边界距离的多任务行为识别方法，主要内容安排如下：在~\ref{32}~节中介绍任务之间的相似性距离计算、目标函数的建立和优化；在~\ref{33}~节中进行实验仿真并对实验结果进行分析；在~\ref{34}~节中对本章内容进行总结。

\begin{figure*}
\begin{center}
\includegraphics[width=1\linewidth]{framework1.eps}
\end{center}
\caption{基于~SVM~的多任务行为识别的主要流程。}
\label{p10}
\end{figure*}

\section{基于~SVM~的多任务行为识别}
\label{32}
\subsection{SVM}

支持向量机（Support Vector Machines, SVM）\upcite{Vapnik95, GuyonVBBS91}是一种二分类模型，它可以在合适的特征空间中为训练样本寻找到间隔最大的分类超平面。Cortes~ 与~Vapnik\upcite{Vapnik95} 于~1995~ 年首先提出了线性支持向量机的概念，随着核函数（kernel function）的引入，学者们提出了非线性的支持向量机。当输入空间为欧式空间与离散集合、特征空间为希尔伯特空间时，核函数表示将输入映射到特征空间得到的特征向量之间的内积。一个线性的支持向量机的目的是从~$n$~维的特征空间中找到一个超平面，如图~\ref{p11}~所示，该超平面可以表示为：
\begin{equation}
\label{f9}
  w^Tx + b = 0.
\end{equation}

一个超平面在二维空间中就是一条直线，SVM~希望通过这条直线将两类数据分割开来。具体来说~SVM~希望根据训练数据找到合适的~$w$~和~$b$~，令~$f(x) = w^Tx + b$~，要求所有在直线~$w^Tx + b = 0$~一侧的样本对应的标签为~$1$~，另一端的样本标签为~$-1$。如图~\ref{p11}~所示，两种颜色的点分别表示两个种类，红色直线表示法向量为~$w$~ 的超平面，每个样本点距超平面的距离可以表示它分类正确的确信度。即越接近超平面的点越不容易被分类，反之，距超平面很远的点则很容易被分辨出其类别。从图中可以观察到，可以将这两种数据线性分类的超平面很多，即可行的~$w$~和~$b$~不是唯一的。正如上文提到的，SVM~中定义了最好的超平面是分类间隔最大的超平面。假设已给定训练集~$X$~ 和超平面~$w^Tx + b = 0$~，则定义超平面~$(w,b)$~关于样本点~$(x_i,y_i)$~的函数间隔为：
\begin{equation}
\label{f10}
\hat{\gamma_i} = y_i(w^Tx_i + b),
\end{equation}
超平面~$w^Tx + b = 0$~对于给定训练集~$X$~的函数间隔被定义为超平面对于~$X$~中所有样本~$(x_i,y_i)$~的函数间隔的最小值，即：
\begin{equation}
\label{f11}
\hat{\gamma} = \min_{i = 1,...,N}\hat{\gamma_i}.
\end{equation}

函数间隔在一定程度上可以表示分类的精确度和确信度。但是在选择超平面时，仅仅有函数间隔还是不够的。因为如果成比例的改变~$w$~和~$b$~为~$3w$~和~$3b$~，函数间隔变成了原来的~3~倍，然而超平面却没有改变。为了避免这一现象，可以通过对超平面的法向量~$w$~ 加一些规范化的约束，例如限制~$\parallel w\parallel = 1$~，使得无论~$w$~ 和~$b$~怎么变化，间隔都是不变的。这使得函数间隔变成了几何间隔。具体来说超平面~$w^Tx + b = 0$~关于样本点~$(x_i,y_i)$~的几何间隔为
\begin{equation}
\label{f12}
\hat{\gamma_i} = y_i(\frac{w^T}{\parallel w\parallel}x_i + \frac{b}{\parallel w\parallel}),
\end{equation}
和函数间隔的定义类似，超平面~$w^Tx + b = 0$~对于给定数据集~$X$~的几何间隔被定义为超平面对于~$X$~中所有样本~$(x_i,y_i)$~的几何间隔之最小值，即
\begin{equation}
\label{f13}
\gamma = \min_{i = 1,...,N}\gamma_i.
\end{equation}

SVM~的目的即根据训练样本寻找能正确划分数据集且几何间隔最大的超平面。对于一个训练数据集而言，可以线性分割数据的超平面可能有很多个，但是几何间隔最大的超平面只有一个，它与其它的超平面相比泛化能力更强，对于未知标签的测试用例有较好的分类预测能力。SVM~具体的损失函数如下所示：
\begin{equation}
\begin{aligned}
\label{f14}
&\min_{w,b} \frac{1}{2}\parallel w\parallel^2, \\
s.t.~y_i(w^Tx_i +&b - 1) \geq 0, i = 1, 2,...,N.
\end{aligned}
\end{equation}

\begin{figure*}
\begin{center}
\includegraphics[width=0.6\linewidth]{10.eps}
\end{center}
\caption{最大几何间隔分类超平面示例，据超平面（红色线）最近的样本点称为支持向量。}
\label{p11}
\end{figure*}

如图~\ref{p11}~所示，支持向量被定义为距离超平面最近的样本点。对于~$y_i = 1$~的样本点，支持向量在超平面~$H_1:w^Tx+b=1$~上，对于~$y_i = -1$~的样本点，支持向量在超平面~$H_2:w^Tx+b = -1$~上。在~$H_1$~和~$H_2$~上的点就是支持向量。从数学的角度来看，支持向量是令公式~\eqref{f14}~成立的样本点，即满足
\begin{equation}
\begin{aligned}
\label{f15}
 y_i(w^Tx_i + b - 1) = 0.
\end{aligned}
\end{equation}

注意到~$H_1$~和~$H_2$~平行，并且没有样本点落在这两条直线之间，$H_1$~和~$H_2$~之间的距离称为间隔。间隔的大小等于~$\frac{2}{\parallel w\parallel}$~，可以看出它只依赖于超平面的法向量~$w$~，$H_1$~和~$H_2$~称为间隔边界。

在决定超平面时只有作为支持向量的样本点才起作用，而其它样本点并没有帮助。如果移动支持向量将改变超平面的位置，但是如果在间隔边界以外移动其他任意样本点，甚至去掉或者添加新的样本点，也对最优超平面不起任何影响。支持向量机名字的由来也是因为支持向量在确定超平面时起着决定性的作用。如果两个类别的差异性很大，很好被区分，那么由训练样本训练得到的~SVM~的几何间隔必定也很大，反之如果两个类别非常相似，那么得到的~SVM~的几何间隔也会很小。所以可以用~SVM~的几何间隔来衡量两个类别之间的相似度。

\subsection{基于~SVM~的相似性度量}
由上文所述，无论是真实世界还是数据库中，不同的行为类别之间都是有关系的。进一步观察发现行为识别数据库中的行为类别存在潜在的结构信息，具体来说我们认为数据库中行为可以分为若干组，相似的行为类别同属于一组且分享特征，反之不属于于同一组的类别不共享特征信息。在上一小节的基础上，我们选择了~SVM~几何间隔作为类别之间的相似性度量，将所有类别之间的相似度矩阵聚类之后得到数据库中潜在的类别结构。

为了将数据库中任意两个行为类别的相似程度量化，我们利用其对应的视频数据为每对行为类别训练~1-VS-1~的SVM。正如上一个小节中提到的，两种行为如果越相似，那么它们对应的~SVM~几何间隔就会越小。我们设~$s_{c_p,c_q}$~为类别~$p$~和~$q$~之间的相似度，则~$s_{c_p,c_q}$~的具体计算公式如下:
\begin{equation}
\label{f16}
s_{c_p,c_q} = \sum_{\forall(i,j)\in c_p\cup c_q}\alpha_i \alpha_j(-1)^{F[c(i),c(j)]}K(x_{p,i}
,x_{q,i}),
\end{equation}
上式中，$i$~和~$j$~表示第~$p$~个类别和第~$q$~个类别交集的样本序号。$x_{p,i}$~表示来自第~$p$~个类别的第~$i$~个样本。$\alpha$~表示支持向量的系数。$\alpha$~ 可以通过训练~SVM~时通过求解最优超平面得到，每一个训练样本都有一个对应的~$\alpha$~值，仅当这个训练样本是支持向量时~$\alpha$~的值不为~$0$。$c(.)$~可以返回给定样本的类标序号。$F[.]$~也是一个函数，它的具体形式如下：
\begin{equation}
\label{f17}
F[c(i),c(j)] = \left\{\begin{matrix}
0 & otherwise \\
1& c[i] \neq c[j],
\end{matrix}\right.
\end{equation}
当样本~$i$~和~$j$~具有相同的类标时，~$F[c(i),c(j)]$~的值为~0，因为我们要计算的是两个类别之间的相似度，当~$i$~和~$j$~来自同一个类时计算距离是没有意义的。

$K(.,.)$~是核函数。核函数在线性模型不可分的情况下可以通过一个非线性变换将训练样本从输入空间映射到一个线性可分的高维空间，从而在高维的空间中寻找几何间隔的超平面。核函数有很多的种类，常用的有多项式核函数（polynomial kernel function）、高斯核函数（Gaussian kernel function）和线性核函数等。在公式~\eqref{f16}~中，核函数的选择应该视特征的种类而定。在本文中我们使用的特征为~Fisher Vector，所以核函数为线性核函数。在时间复杂度方面，由于每个~1-VS-1~的~SVM~只需要用到两个类别对应的训练样本，所以即使总共需要训练~$\binom{2}{C}$~个分类器，但是总体速度还是很快的。我们的实验过程中发现在~HMDB51~数据库中训练~$\binom{2}{51}$~个~1-VS-1~ SVMs所花费的时间不到1秒。

通过对数据库中的每对类别训练~1-VS-1~的~SVM~并根据公式~\eqref{f16}~计算相似度，最终可以得到数据库中所有类别对应的相似度矩阵~$\mathbf{S} \in \mathbb{R}^{C \times C}$~，这是一个对称矩阵，且~$s_{p, q}$~代表了第~$p$~个类别和第~$q$~个类别的相似度，$s_{p, q}$~越小，说明这两个类越相似，反之亦然。得到相似度矩阵~$\mathbf{S}$~ 之后，我们利用近邻传播聚类（Affinity Propagation Clustering）~\upcite{frey07affinitypropagation}得到了数据库中隐含的类别结构信息。值得注意的是，我们不需要提前决定聚类结构中簇的数量，它可以基于相似度矩阵~$\mathbf{S}$~ 在计算过程中被决定。这么做的原因有两点，首先仅凭肉眼或者人工的感觉来判断行为类别结构是不准确的，视觉信息不相似的行为类别有时也会共享相似的运动轨迹等特征。所以人工的判断数据库中行为组的个数是不准确的，不仅如此，工作量还非常的大。此外，根据公式~\eqref{f16}~可以看出类别之间相似性矩阵是基于特征计算的。具体来说，对于不同的特征，例如方向梯度直方图（Histograms of Oriented Gradients, HOG）和光流场方向直方图（Histograms of Optical Flow, HOF），得到的~SVMs~和相似度矩阵~$\mathbf{S}$~ 也是不同的，那么其对应的类别组结构也是不同的。总而言之，对于一个行为识别数据库而言，并不存在一个最优的组结构，组的个数和每个组内具体的行为类别是随特征类型的变化而变化的。

在~Hou Rui\upcite{HouZSS14} 的工作中，也利用到了基于~SVM~的相似性度量。但是与他们的工作相比，我们的方法在应用和构造上都有所创新和改变。Hou Rui~通过计算~SVM~ 几何间隔来找到每个类别的相似类别，从而学习到高级语义上的判别性特征。然而我们通过计算基于~SVM~的相似度来探索潜藏在数据库中的类别结构信息，从而可以用其约束多任务学习鼓励同一个组内的类别共享特征信息。
\subsection{目标函数的建立和优化}
基于~SVM~的多任务行为识别的具体流程如图~\ref{p10}~所示。如果将数据库中的行为类别视为任务，通过观察我们发现这些任务之间是有关系的。我们假设任务可以分为若干组，每个组内的任务都是相似的且共享相同的特征空间，不同组内的任务存在特征排斥和竞争。为了求得任务的结构信息，我们对每对任务训练~1-VS-1~的~SVM，利用公式~\eqref{f16}~计算每对任务之间的相似性距离，得到相似性矩阵~$\mathbf{S}$，然后通过聚类得到基于训练特征的最优任务结构，我们把该结构作为先验信息，利用基于组结构约束的多任务学习框架同时学习每个任务对应的二元线性分类器。

假设在给定行为数据库中共有~$C$~类行为类别。对于第~$c$~类别，对应的训练样本为~$\{\mathbf{x}_{c,i},y_{c,i}\}_{i=1}^{N_c} \subset \mathbb{R}^{D \times 1}(c=1,...,C)$，其中~$i$~表示第~$c$~个类别的视频样本的序号，$N_c$~表示属于第~$c$~个类别的样本总量。$\mathbf{x}_{p,i}$~表示来自第~$p$~个类别的第~$i$~个样本的~$D$~维特征向量，$y_{c,i}$~ 为其对应的标签。且假设通过聚类之后可将任务总共分为~$L$~组。则具体的目标函数如下：
\begin{equation}
\label{fgroup}
\min_W \sum_{c=1}^C \sum_{i=1}^{N_c} \frac{1}{2} \left[ \max(0,1-y_{c,i}\mathbf{w}_c \mathbf{x}_{c,i}) \right] ^2 + \lambda_1\sum_{d=1}^D \sum_{l=1}^{L}\Vert \mathbf{w}^{d,g_l} \Vert _2+\lambda_2\Vert \mathbf{W}\Vert _F^2,
\end{equation}
上式中的第一项为铰链损失函数（hinge loss function）。$\mathbf{W}\in\mathbb{R}^{N \times D}$~表示所有任务对应的二元线性分类器的参数矩阵，$\mathbf{w}_c \in \mathbb{R}^D$~ 表示第~$c$~个任务的分类参数。第二项为基于组结构的正则项，其中~$\mathbf{w}^{d,g_l}$~是一个行向量，它表示属于第~$g_l$~个组的所有任务对应第~$d$~ 维特征的分类参数。基于组结构的正则项同时利用了~$\ell_1$~范数和~$\ell_{2,1}$~范数的优点，从而鼓励组内的特征共享和组间的特征竞争。最后一项为~F~范数（frobenius norm）可以防止分类矩阵~$\mathbf{W}$~过拟合。$\lambda_1$~和~$\lambda_2$~是用来控制稀疏与分类损失函数的平衡因子。

很明显可以看出，用于约束公式~\eqref{fgroup}~的组结构正则项~$\sum_{d=1}^D \sum_{l=1}^{L}\Vert \mathbf{w}^{d,g_l} \Vert _2$~是一个混合范数正则项。尽管它是凸的，但是它优化起来却是非平稳的。首先我们将该正则项表示为其对偶形，再利用平滑梯度下降算法\upcite{CLK12}优化目标函数的平滑近似形式。

优化求解公式~\eqref{fgroup}~之后可以得到每一个行为类别对应的二元线性分类参数~$\mathbf{w}_c$。 这时对于一个新的测试视频，首先对它提取特征~$\mathbf{x}_n \in \mathbb{R}^D$，它对应的标签~$y_n$~可由以下的公式得到：
\begin{equation}
\label{fpredict}
y_n = \arg \max_c \mathbf{w}_c \mathbf{x}_n.
\end{equation}

Dinesh Jayaraman等\upcite{JayaramanSG14}也利用了基于组结构约束的多任务学习方法，他通过将属性视为任务来同时对每个属性学习分类模型。基于~SVM~的多任务行为识别方法与他们的工作对比，有如下不同之处：（1）首先前者中任务的组结构是人工分割的。Dinesh Jayaraman~ 通过将描述同类事物的属性分为一组，例如描述颜色的属性同属一组，它们之间共享描述颜色的特征。这种做法的先验假设太强，而且可能忽视任务之间潜藏的肉眼不可见的信息，所以我们的方法提出了利用~SVM~几何间隔来衡量任务之间的相似度。（2）我们的方法利用了~$\ell_2$~范数来防止分类矩阵过拟合，提高了模型的泛化能力。

\section{实验结果与分析}
\label{33}
本小节先介绍了实验中所用数据库、特征、基准方法和参数选择等细节。然后展示了基于~SVM~的多任务行为识别和对比方法分别在行为识别数据库~HMDB51~和~UCF50~的结果，并给出了结果的分析。
\subsection{实验设计}
\label{331}
为了证明基于~SVM~的多任务行为识别方法是有效的，我们将在行为识别数据库~HMDB51\upcite{Kuehne11}和~UCF50\upcite{ReddyS13}上与多种基准方法和目前行为识别领域中~state-of-the-art~的一些方法进行对比实验，下面将依次介绍数据库、特征、参数和基准方法。

HMDB51~数据库中总共包含~6766~个视频，它们分别来自~51~个行为类别，且平均每个类别包含~100~个以上的视频样本。如图~\ref{p12}~所示，所有的样本都是在真实环境下拍摄而得的，比如电影、视频网站等。由于视角、尺寸、背景和光照等因素，HMDB51~中即使属于同一类的视频差别也非常大。HMDB51~对于行为识别而言是非常困难的数据库。在数据库的主页上提供了三种训练集和测试集的分割方法，我们的实验也建立在这三种数据分割方法之上，并且最终给出了平均分类精度。

UCF50~总共包含~6617~个视频，它们分别来自~50~个行为类别。所有的视频都来自于~Youtube。 我们的、对于训练数据、验证数据还有测试数据的划分都依照了~\cite{SadanandC12,ZhouWJZ13}~中的步骤。~UCF50~的部分视频样本示例如图~\ref{p14}~所示。

\begin{figure*}
\begin{center}
\includegraphics[width=0.8\linewidth]{11.eps}
\end{center}
\caption{HMDB51~中的样本示例。}
\label{p12}
\end{figure*}

\begin{figure*}
\begin{center}
\includegraphics[width=0.8\linewidth]{ucf50.eps}
\end{center}
\caption{UCF50~中的样本示例。}
\label{ucf50}
\end{figure*}

在我们的实验中，我们利用了~improved dense trajectories\upcite{Wang2013}~来提取局部描述子。首先在连续帧中跟踪兴趣点，然后在轨迹的领域中提取~HOG~、HOF~、MBHx~ 和~MBHy~四种类型的描述子。和文献~\citep{WangUKLS09}~中的步骤一样，我们首先利用~PCA~将每种描述子的维度降到一半。然后随机选取~256000~个特征，通过~EM~算法学习到由~512~个高斯函数组成的高斯混合模型，从而将描述子转化为~Fisher Vector~的形式。在对~Fisher Vector~进行白化\upcite{JegouC12}、$L_2$~正规化和~intra~正规化之后，得到了最终的特征。在我们的实验中，分别给出了四种类型的描述子单独训练的情况，也给出了将这四种特征串联起来的情况。

在公式~\eqref{fgroup}~中的~$\lambda_1$~和~$\lambda_2$~的最优值通过交叉验证选出。而数据库的类别组的最优个数由聚类算法根据不同的特征得到。

我们提出了~3~种基准方法，分别为不加正则项的多任务行为识别，基于~$\ell_{1}$~范数的多任务行为识别，基于~$\ell_{2,1}$~范数的多任务行为识别。在所有的多任务行为识别方法中，我们选择~Hinge loss~作为损失函数。

\subsection{实验结果}
\newcommand{\tabincelll}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\zihao{5}
\begin{table}
\begin{center}
\caption{基于~SVM~的多任务学习与基准方法在~HMDB51~上的实验结果对比。}
\label{b1}
\begin{tabular}{|p{1.9cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|}
\hline
特征/方法 & \tabincell{c}{多任务行为识别}& \tabincell{c}{基于~$\ell_1$~范数的 \\ 多任务行为识别} &\tabincell{c}{基于~$\ell_{2,1}$ 范数的 \\ 多任务行为识别}  & \tabincell{c}{基于~SVM~\\ 多任务行为识别} \\
\hline
HOG & 40.22 & 42.05 & 41.84 & \textbf{43.22} \\
\hline
HOF & 49.00 & 50.04 & 50.09 & \textbf{50.62} \\
\hline
MBHx & 40.24 & 41.81 & 41.61 & \textbf{42.35} \\
\hline
MBHy & 47.13 & 47.62 & 47.02 & \textbf{47.98} \\
\hline
combined & 60.15 & 60.38 & 60.31 & \textbf{60.54} \\
\hline
\end{tabular}
\end{center}
\end{table}
\zihao{-4}\setlength{\baselineskip}{20pt}
首先我们给出了当四种特征串联时，通过聚类将~51~个行为类别划分得到的组结构，具体为组~1: \textit{turn, walk, shake hands, hug and kiss.} 组~2: \textit{brush hair, clap, wave, shoot gun, draw sword, sword, climb, climb stairs, drink, eat, pick, sit, stand, pour, shoot bow and pullup.} 组~3: \textit{chew, smile, laugh, smoke and talk.} 组~4: \textit{push up and sit up.} 组~5: \textit{cartwheel, flic flac, hand stand, somersault, push, ride bike and ride horse.} 组~6: \textit{catch, hit, swing baseball, throw, dive, fall floor, jump, run, kick ball, fencing, kick, sword exercise, punch, dribble, shoot ball and golf.} 通过这个结果可以看出在视觉和行为轨迹上相似的行为大致被分到了一组。比如，行为~chew,~smile,~laugh,~smoke~和~talk~这些描述面部的微小特征的行为被分到了同一组。

然后我们比较了基于~SVM~的多任务行为识别和基准方法在~HMDB51~上的识别精度，具体结果如表~\ref{b1}~所示。通过结果可以看出基于~SVM~ 间隔的多任务行为识别无论用哪种类型的特征，效果都比其它的多任务学习框架要好。当所有的行为类别都属于同一个组的时候，也就是所有的类别都相似的情况下，公式~\eqref{fgroup}~中的结构正则项退化为~$\ell_{2,1}$~范数。当所有的行为类别都自成一组时，也就是所有的类别之间都不共享特征的情况下，结构正则项退化为~$\ell_{1}$~范数。所以组结构约束综合了~$\ell_{1}$~范数和$~\ell_{2,1}$~范数的优点，这也为该方法优于其它多任务学习方法的行为识别提供了理论基础。

最后我们把基于~SVM~的多任务行为识别和行为识别领域中一些~state-of-the-art~方法在~HMDB51~数据库上做了对比试验。如表~\ref{b2}~所示，基于~SVM~间隔的多任务行为识别甚至比基于深度学习的方法\upcite{SimonyanZ14}效果还要好。
\zihao{5}
\begin{table*}
\begin{center}
\caption{基于~SVM~的多任务行为识别方法与~state-of-the-art~方法在~HMDB51~上的实验结果对比。}
\label{b2}
\begin{tabular}{|p{7cm}<{\centering}|p{3cm}<{\centering}|}
\hline
Methods & Accuracy \\
\hline
Sadanand and J.Corso\upcite{SadanandC12} & $26.9 \%$ \\
\hline
Yang et al.\upcite{YangT14} & $53.9 \%$\\
\hline
Hou et al.\upcite{HouZSS14} & $57.88 \%$ \\
\hline
K. Simonyan and A. Zisserman\upcite{SimonyanZ14} & $59.5 \%$ \\
\hline
基于~SVM~间隔多任务行为识别  & $\textbf{60.54} \%$ \\
\hline
\end{tabular}
\end{center}
\end{table*}
\zihao{-4}\setlength{\baselineskip}{20pt}
\zihao{5}
\begin{table}[!h]
\begin{center}
\caption{基于~SVM~的多任务行为识别与基准方法在~UCF50~上的实验结果对比。}
\label{ucf501}
\begin{tabular}{|p{1.9cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|p{2.8cm}<{\centering}|}
\hline
特征/方法 & \tabincell{c}{多任务行为识别}& \tabincell{c}{基于~$\ell_1$~范数的 \\ 多任务行为识别} &\tabincell{c}{基于~$\ell_{2,1}$~范数的 \\ 多任务行为识别}  & \tabincell{c}{基于~SVM~的\\ 多任务行为识别} \\
\hline
HOG&82.37&82.76&82.98&\textbf{83.64}\\
\hline
HOF&85.69&86.57&86.89&\textbf{87.33}\\
\hline
MBHx&83.18&83.74&83.53&\textbf{83.95}\\
\hline
MBHy&84.07&85.08&85.32&\textbf{85.88}\\
\hline
combined&87.83&88.39&88.54&\textbf{88.96}\\
\hline
\end{tabular}
\end{center}
\end{table}
\zihao{-4}\setlength{\baselineskip}{20pt}

\zihao{5}
\begin{table*}[!h]
\begin{center}
\caption{基于~SVM~的多任务行为识别与~state-of-the-art~方法在~UCF50~上的实验结果对比。}
\label{ucf502}
\begin{tabular}{|c|c|}
\hline
Methods & Accuracy\\
\hline
Sadanand and J.Corso\upcite{SadanandC12} & 57.9 $\%$ \\
\hline
Kishore K. Reddy and Mubarak Shah\upcite{ReddyS13} & 76.9$\%$\\
\hline
Zhou et al.\upcite{ZhouWJZ13}& 78.3$\%$\\
\hline
Wang et al.\upcite{Wang2013} & 85.9$\%$\\
\hline
Proposed Method & \textbf{88.96}$\%$\\
\hline
\end{tabular}
\end{center}
\end{table*}
\zihao{-4}\setlength{\baselineskip}{20pt}

如表~\ref{ucf501}~所示，我们在数据库~UCF50~上比较了基于~SVM~的多任务行为识别与三个基准方法的识别精度。从表中的结果可以看出，基于~SVM~的多任务行为识别无论是用哪个类型的描述子训练模型，与基准方法相比识别精度都是最高的。这个结果与我们在~HMDB51~上的结果一致，也再一次证明了上文中的分析：组结构约束正则项结合了~$\ell_{1}$~ 范数和~$\ell_{2,1}$~ 范数的优点。

最后，我们在表~\ref{ucf502}~中展示了基于~SVM~的多任务行为识别和行为识别领域一些~state-of-the-art~方法在~UCF50~数据库上的识别精度。可以看出，我们的方法仍旧保持了一定的先进性。在这些方法中，Wang\upcite{Wang2013}等人的工作忽略了行为之间的关系，直接利用~Fisher Vector~ 特征训练~SVM~实现了行为识别，实验结果表示了多任务学习的重要性。Qiang Zhou\upcite{ZhouWJZ13} 等人的工作和我们提出的方法略为相似。他们的工作本文在~\ref{232}~小节中已做了简单的介绍。Qiang Zhou~ 提出了一种基于多任务学习框架的行为识别方法，他们认为任务之间分享的基任务可以视为不同的行为类别之间共享的运动元素。比如跑步、走路、挥手等运动其实都是由身体部位的基本移动构成的。最终每个类别的分类器参数由基任务线性组合而成。和他们的工作相比，我们的方法通过训练~SVM~来寻找潜藏在数据库中的行为结构，最后在~Qiang Zhou~ 的工作中共有~3~ 个参数需要调节，而且基任务的个数需要事先确定，而基于~SVM~的多任务行为识别的参数个数比较少，而且由于近邻传播聚类的使用，行为组的个数也不用事先确定。



\section{本章小结}
\label{34}
之前绝大部分的人体行为识别方法都将行为类别当做了独立的任务，分别对每个类别独立地训练其对应的分类器。然而通过观察可以发现无论是在数据库中还是在现实生活中，类别之间都是有关系的。相似的类别之间分享相同的视觉信息特征和运动轨迹特征。所以独立地为每个类别训练分类器会浪费掉它们之间共享的信息。另一方面，现存的几种多任务行为识别方法认为所有行为之间共享同一个特征空间，这个假设对绝大部分情况都不太现实，可能会导致“负迁移”损害模型性能。通过观察可以发现，数据库中行为类别的关系有亲疏之分，相似程度高的行为可以分为一组，共享相同的特征空间。本章的研究重点在于挖掘数据库中行为类别的潜在结构关系，提出了基于~SVM~的多任务行为识别。具体来说，首先对于数据库中的每对行为训练一个~1-VS-1~的~SVM，通过利用得到的支持向量等结果计算两个行为之间的~SVM~几何间隔，并用其来衡量行为之间的相似度；SVM~几何间隔越小，说明行为之间相似度越高，分享的共同信息越多，反之亦然；随后将所有类别对应的相似度矩阵聚类得到类别中潜在的结构关系；通过将此结构关系作为先验正则项与多任务学习框架结合，鼓励存在于一组内的行为类别共享特征，而不在一组内的行为类别之间进行特征竞争。通过在~HMDB51~和~UCF50~数据库上进行实验，可以表明基于~SVM~的多任务行为识别较之行为识别领域一些先进的方法的优越性。这表明了利用行为类别之间的信息，寻找行为类别之间潜在的行为结构是必要的。
